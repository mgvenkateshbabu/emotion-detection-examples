{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fcac56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import pathlib\n",
    "\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "base_path = \"CK+48\"\n",
    "files=os.listdir(base_path)\n",
    "\n",
    "\n",
    "emotions=['anger', 'contempt', 'disgust', 'fear', 'happy', 'sadness', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ef9fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "count_file_under_emotions=[]\n",
    "images=[]\n",
    "labels=[]\n",
    "for emotion_dir in files:\n",
    "    idx=emotions.index(emotion_dir)\n",
    "    label=idx\n",
    "    i=0\n",
    "  \n",
    "    one_emotion_dir = base_path + '/' + emotion_dir\n",
    "    files_under_one_emotion = os.listdir(one_emotion_dir)\n",
    "    for file_under_one_emotion in files_under_one_emotion:\n",
    "        file_main=one_emotion_dir+'/'+file_under_one_emotion\n",
    "        #print(file_main+\"   \"+str(label))\n",
    "        image= cv2.imread(file_main)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image= cv2.resize(image,(48,48))\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        i+=1\n",
    "    count_file_under_emotions.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58cf20ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[135, 54, 177, 75, 207, 84, 249]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_file_under_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eddf275b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d50209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.layers import Input,Activation,Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def conv_layers(input_tensor, filters):\n",
    "    \n",
    "    x = Conv2D(filters=filters,kernel_size=(3, 3),padding = 'same',strides=(1, 1),kernel_regularizer=l2(0.001))(input_tensor)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x= Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_model(input_shape):\n",
    "    inputs = Input((input_shape))\n",
    "\n",
    "    conv_1= conv_layers(inputs,32)\n",
    "    maxp_1 = MaxPooling2D(pool_size = (2,2)) (conv_1)\n",
    "    conv_2 = conv_layers(maxp_1,64)\n",
    "    maxp_2 = MaxPooling2D(pool_size = (2, 2)) (conv_2)\n",
    "    conv_3 = conv_layers(maxp_2,128)\n",
    "    maxp_3 = MaxPooling2D(pool_size = (2, 2)) (conv_3)\n",
    "    conv_4 = conv_layers(maxp_3,256)\n",
    "    maxp_4 = MaxPooling2D(pool_size = (2, 2)) (conv_4)\n",
    "    flatten= Flatten() (maxp_4)\n",
    "    dense_1= Dense(128,activation='relu')(flatten)\n",
    "    drop_1=Dropout(0.2)(dense_1)\n",
    "    output= Dense(7,activation=\"sigmoid\")(drop_1)\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6523e571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 684,359\n",
      "Trainable params: 684,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model((48,48,3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b6b3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "images_arr = np.array(images)\n",
    "labels_arr = np.array(labels)\n",
    "images_scaled_arr = images_arr/255\n",
    "\n",
    "labels_encoded = tf.keras.utils.to_categorical(labels_arr, num_classes=len(emotions))\n",
    "\n",
    "X_train, X_non_train, Y_train, Y_non_train= train_test_split(images_scaled_arr, labels_encoded, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d196022d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22/22 [==============================] - 6s 271ms/step - loss: 1.8622 - accuracy: 0.3343 - val_loss: 1.8012 - val_accuracy: 0.4228\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.80117, saving model to age-gender-CKPLUS/model\\model-emotions-ep001-loss1.862-val_loss1.801.h5\n",
      "Epoch 2/2\n",
      "22/22 [==============================] - 5s 230ms/step - loss: 1.4859 - accuracy: 0.4979 - val_loss: 1.4521 - val_accuracy: 0.5041\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.80117 to 1.45205, saving model to age-gender-CKPLUS/model\\model-emotions-ep002-loss1.486-val_loss1.452.h5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 1.3394 - accuracy: 0.6146\n",
      "Accuracy: 61.45833134651184%\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 2\n",
    "\n",
    "checkpoint_pattern = ('model/model-emotions-ep{epoch:03d}-loss{loss:.3f}'\n",
    "                          '-val_loss{val_loss:.3f}.h5')\n",
    "\n",
    "checkpoint = ModelCheckpoint(checkpoint_pattern,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "\n",
    "\n",
    "train_augmenter = ImageDataGenerator(rotation_range=10,\n",
    "                                     zoom_range=0.1,\n",
    "                                     horizontal_flip=True,                                     \n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "train_gen = train_augmenter.flow(X_train,\n",
    "                                 Y_train,\n",
    "                                 batch_size=BATCH_SIZE)\n",
    "\n",
    "train_steps = len(X_train) // BATCH_SIZE\n",
    "\n",
    "val_augmenter = ImageDataGenerator(rotation_range=10,\n",
    "                                     zoom_range=0.1,\n",
    "                                     horizontal_flip=True,                                     \n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "X_valid = X_non_train[:len(X_non_train)//2]\n",
    "Y_valid = Y_non_train[:len(X_non_train)//2]\n",
    "\n",
    "X_test = X_non_train[len(X_non_train)//2:]\n",
    "Y_test = Y_non_train[len(X_non_train)//2:]\n",
    "\n",
    "val_gen = val_augmenter.flow(X_valid,\n",
    "                             Y_valid,\n",
    "                             batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "model.fit(train_gen,\n",
    "          steps_per_epoch=train_steps,\n",
    "          validation_data=val_gen,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=1,\n",
    "          callbacks=[checkpoint])\n",
    "\n",
    "test_augmenter = ImageDataGenerator(rotation_range=10,\n",
    "                                     zoom_range=0.1,\n",
    "                                     horizontal_flip=True,                                     \n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "test_gen = test_augmenter.flow(X_test,\n",
    "                               Y_test,\n",
    "                               batch_size=BATCH_SIZE)\n",
    "test_steps = len(X_test) // BATCH_SIZE\n",
    "_, accuracy = model.evaluate(test_gen, steps=test_steps)\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "931aa5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\venka\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\venka\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "i=0 \n",
    "Y_test_label = [] \n",
    "predictions_label = []\n",
    "\n",
    "for i in range(len(predictions)):   \n",
    "    Y_test_label.append(int(np.argmax(Y_test[i])))     \n",
    "    predictions_label.append(int(np.argmax(predictions[i])))   \n",
    "\n",
    "report = classification_report(Y_test_label, predictions_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b987660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def test_image(ind):\n",
    "    plt.imshow(images_arr[ind])\n",
    "    image_test = images_arr[ind]\n",
    "    print(\"Label actual:  \" + emotions[labels[ind]])\n",
    "    pred = model.predict(np.array([images_arr[ind]]))\n",
    "    #print(pred_1)\n",
    "    pred_class = emotions[int(np.argmax(pred))]\n",
    "    print(\"Predicted Label: \"+ pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c20a9932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label actual:  surprise\n",
      "Predicted Label: fear\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image(789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209f783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
